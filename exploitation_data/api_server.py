"""
API Flask pour l'analyse statistique de comparaison de colonnes.
Contient les fonctions de détection de type, de recommandation, et d'exécution de l'analyse (Corrélation, Chi-Deux, ANOVA/T-Test, Graphique).

timerr !!!!!
"""
import pandas as pd
import numpy as np
from scipy.stats import chi2_contingency, f_oneway 
from typing import Tuple, Dict, Any
from flask import Flask, request, jsonify
import traceback 
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt 
import os # 

# ======================================================================
# ÉTAPE 2: DÉTECTION DU TYPE DE VARIABLE
# ======================================================================

def determine_data_type(series: pd.Series, 
                        categorical_threshold: float = 0.05, 
                        max_unique_binary: int = 2) -> Tuple[str, float]:
    """ Détermine le type statistique et le taux de données manquantes. """
    if series.empty: return 'Empty', 0.0
    n_rows = len(series)
    unique_count = series.nunique(dropna=True)
    missing_rate = series.isnull().mean()
    
    if pd.api.types.is_datetime64_any_dtype(series): return 'Datetime', missing_rate
    if pd.api.types.is_numeric_dtype(series):
        if unique_count <= max_unique_binary: return 'Binary', missing_rate
        return 'Numeric', missing_rate
    if unique_count <= max_unique_binary: return 'Binary', missing_rate
    if unique_count / n_rows < categorical_threshold: return 'Categorical', missing_rate
    return 'Text', missing_rate

# ======================================================================
# ÉTAPE 3: MATRICE DE DÉCISION DE COMPARAISON
# ... (Fonksiyon aynı) ...
# ======================================================================

def get_comparison_recommendations(type_a: str, type_b: str, 
                                   missing_rate_a: float, missing_rate_b: float) -> Dict[str, Any]:
    """ Détermine les recommandations d'analyse. """
    
    statu = "Non Déterminé" 
    analyse = "Aucune Recommandation" 
    visuale = "Aucun" 
    attation_sup = [] 
    tranformation_possibe = [] 

    if missing_rate_a > 0.25 or missing_rate_b > 0.25:
        attation_sup.append(f"ALERTE: La variable A ({missing_rate_a*100:.1f}%) et/ou B ({missing_rate_b*100:.1f}%) a un taux de données manquantes (>25%) très élevé.")
    
    if (type_a == 'Numeric' or type_a == 'Binary') and (type_b == 'Numeric' or type_b == 'Binary'):
        analyse = "Analyse de Corrélation (Pearson/Spearman) et Régression"
        visuale = "Diagramme de Dispersion (Scatter Plot), Carte Thermique (Heatmap)"
        statu = "Comparable (Test de Relation et de Direction)"
    
    elif (type_a == 'Numeric' and ('Categorical' in [type_b] or 'Binary' in [type_b])) or \
         (('Categorical' in [type_a] or 'Binary' in [type_a]) and type_b == 'Numeric'):
        analyse = "Test T pour Échantillons Indépendants ou ANOVA"
        visuale = "Diagramme en Boîte (Box Plot), Diagramme en Violon (Violin Plot)"
        statu = "Comparable (Test de Différence entre les Moyennes de Groupes)"

    elif ('Categorical' in [type_a, type_b] or 'Binary' in [type_a, type_b]):
        analyse = "Test d'Indépendance (Test du Chi-Deux), Mesures d'Association (V de Cramer)"
        visuale = "Graphique à Barres Groupées (Bar Chart), Diagramme Mosaïque (Mosaic Plot)"
        statu = "Comparable (Test d'Indépendance des Variables)"
        
    elif 'Text' in [type_a, type_b]:
        analyse = "La comparaison statistique directe n'est pas possible."
        statu = "Incompatible"

    else:
        statu = "Incompatible ou Combinaison Non Définie"
        
    return {
        "Statut": statu,
        "Type_Variable_A": type_a,
        "Type_Variable_B": type_b,
        "Analyse_Suggeree": analyse,
        "Visualisation_Suggeree": visuale,
        "Avertissement_Suppl": attation_sup if attation_sup else "Aucun avertissement de base trouvé."
    }


# ======================================================================
# ÉTAPE 4: EXÉCUTION DE L'ANALYSE ET GÉNÉRATION DU GRAPHIQUE
# ======================================================================

def analyze_comparison(df: pd.DataFrame, col_a: str, col_b: str) -> Dict[str, Any]:
    """ Exécute l'analyse et génère les résultats statistiques ve le chemin du graphique. """
    if col_a not in df.columns or col_b not in df.columns:
        return {"error": "La/les colonne(s) sélectionnée(s) n'ont pas été trouvées dans le DataFrame."}

    # 1. Type Tespiti
    type_a, missing_rate_a = determine_data_type(df[col_a])
    type_b, missing_rate_b = determine_data_type(df[col_b])
    
    # 2. Öneri Alma
    result = get_comparison_recommendations(type_a, type_b, missing_rate_a, missing_rate_b)
    result["Resultats_Analytiques"] = {}
    
  
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    GRAPH_FOLDER_SAVE = os.path.join(BASE_DIR, "graphs")  # absolute filesystem path

    GRAPH_FOLDER_HTTP = "graphs/"
    GRAPH_FILENAME = f"graph_{col_a}_{col_b}.png"


    GRAPH_SAVE_PATH = os.path.join(GRAPH_FOLDER_SAVE, GRAPH_FILENAME)

    GRAPH_URL_RETURN = (GRAPH_FOLDER_HTTP + GRAPH_FILENAME).replace('\\', '/')
    
    
    # --- KLASÖR OLUŞTURMA KONTROLÜ ---
    try:
        # Klasörü oluştururken, Python kendi bulunduğu yerdeki 'graphs/' klasörüne bakar.
        if not os.path.exists(GRAPH_FOLDER_SAVE):
            os.makedirs(GRAPH_FOLDER_SAVE)
    except Exception as e:
        result["Resultats_Analytiques"]["Erreur_Creation_Dossier"] = f"Impossible de créer le dossier 'graphs': {str(e)}"
    # -------------------------------------------------------------
    
    
    # --- Corrélation (Numérique vs Numérique) ---
    is_numeric_vs_numeric = (type_a == 'Numeric' or type_a == 'Binary') and (type_b == 'Numeric' or type_b == 'Binary')
    if is_numeric_vs_numeric:
        try:
            correlation = df[[col_a, col_b]].corr(method='pearson').iloc[0, 1]
            result["Resultats_Analytiques"]["Correlation_Pearson"] = round(correlation, 4)
            if abs(correlation) >= 0.7: result["Resultats_Analytiques"]["Interpretation"] = "Forte relation linéaire."
            elif abs(correlation) >= 0.3: result["Resultats_Analytiques"]["Interpretation"] = "Relation linéaire modérée."
            else: result["Resultats_Analytiques"]["Interpretation"] = "Relation linéaire faible ou inexistante."

            # GÖRSEL OLUŞTURMA: Scatter Plot
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.scatter(df[col_a], df[col_b])
            ax.set_title(f'Diagramme de Dispersion: {col_a} vs {col_b}')
            ax.set_xlabel(col_a)
            ax.set_ylabel(col_b)
            plt.tight_layout()
            plt.savefig(GRAPH_SAVE_PATH) 
            plt.close(fig)
            
            result["Resultats_Analytiques"]["Graphique_Fichier"] = GRAPH_URL_RETURN

        except Exception as e:
            result["Resultats_Analytiques"]["Erreur_Calcul_Correlation"] = str(e)
            result["Resultats_Analytiques"]["Erreur_Graphique"] = "Impossible de générer le graphique: " + str(e)


    # --- Chi-Deux (Catégorique vs Catégorique) ---
    is_categorical_vs_categorical = ('Categorical' in [type_a, type_b] or 'Binary' in [type_a, type_b])
    if is_categorical_vs_categorical and is_categorical_vs_categorical:
        try:
            clean_df = df[[col_a, col_b]].dropna()
            contingency_table = pd.crosstab(clean_df[col_a], clean_df[col_b])
            
            # Hesaplamalar
            chi2, p, dof, expected = chi2_contingency(contingency_table)
            n_obs = contingency_table.sum().sum()
            min_dim = min(contingency_table.shape) - 1
            cramers_v = np.sqrt(chi2 / (n_obs * min_dim)) if min_dim > 0 and n_obs > 0 else 0
            
            result["Resultats_Analytiques"]["Chi2_Statistique"] = round(chi2, 4)
            result["Resultats_Analytiques"]["P_Valeur"] = p
            result["Resultats_Analytiques"]["Cramers_V"] = round(cramers_v, 4)
            result["Resultats_Analytiques"]["Degres_Liberte"] = dof
            if p < 0.05: result["Resultats_Analytiques"]["Interpretation_Hypothese"] = "Les variables sont probablement dépendantes (p < 0.05)."
            else: result["Resultats_Analytiques"]["Interpretation_Hypothese"] = "Aucune preuve suffisante pour rejeter l'indépendance (p >= 0.05)."

            # GÖRSEL OLUŞTURMA: Bar Chart
            fig, ax = plt.subplots(figsize=(10, 6))
            contingency_table.plot(kind='bar', stacked=False, ax=ax)
            ax.set_title(f'Relation entre {col_a} et {col_b}', fontsize=14)
            ax.set_ylabel('Fréquence (Nombre)', fontsize=12)
            ax.set_xlabel(col_a, fontsize=12)
            ax.tick_params(axis='x', rotation=45) 
            plt.legend(title=col_b)
            plt.tight_layout()
            plt.savefig(GRAPH_SAVE_PATH) 
            plt.close(fig)

            result["Resultats_Analytiques"]["Graphique_Fichier"] = GRAPH_URL_RETURN

        except Exception as e:
            result["Resultats_Analytiques"]["Erreur_Calcul_Chi2"] = f"Calcul Chi2 impossible: {str(e)}"
            result["Resultats_Analytiques"]["Erreur_Graphique"] = "Impossible de générer le graphique: " + str(e)

    
    # --- T-Test/ANOVA (Numérique vs Catégorique/Binaire) ---
    is_numeric_vs_categorical = (type_a == 'Numeric' and ('Categorical' in [type_b] or 'Binary' in [type_b])) or \
                                (type_b == 'Numeric' and ('Categorical' in [type_a] or 'Binary' in [type_a]))
    if is_numeric_vs_categorical:
        
        num_col = col_a if type_a == 'Numeric' else col_b
        cat_col = col_b if type_b != 'Numeric' else col_a
        
        try:
            clean_df = df[[num_col, cat_col]].dropna()
            groups = [group[num_col].values for name, group in clean_df.groupby(cat_col)]
            
            if len(groups) >= 2 and all(len(g) > 1 for g in groups):
                f_statistic, p_anova = f_oneway(*groups)
                
                result["Resultats_Analytiques"]["Test_Utilise"] = "ANOVA (F-test)" if len(groups) > 2 else "T-Test (via F-test)"
                result["Resultats_Analytiques"]["F_Statistique"] = round(f_statistic, 4)
                result["Resultats_Analytiques"]["P_Valeur_ANOVA"] = p_anova
                
                if p_anova < 0.05:
                    result["Resultats_Analytiques"]["Interpretation_Hypothese"] = "Il existe une différence significative entre au moins deux moyennes de groupe (p < 0.05)."
                else:
                    result["Resultats_Analytiques"]["Interpretation_Hypothese"] = "Aucune preuve suffisante pour établir une différence significative entre les moyennes (p >= 0.05)."
            else:
                 result["Resultats_Analytiques"]["Note"] = "Pas assez de groupes ou de données par groupe pour effectuer l'ANOVA."
        
            # GÖRSEL OLUŞTURMA: Box Plot
            fig, ax = plt.subplots(figsize=(10, 6))
            df.boxplot(column=num_col, by=cat_col, ax=ax)
            plt.title(f'Distribution de {num_col} par {cat_col}')
            plt.suptitle('') # Üst başlığı kaldır
            plt.xlabel(cat_col)
            plt.ylabel(num_col)
            plt.tight_layout()
            plt.savefig(GRAPH_SAVE_PATH) 
            plt.close(fig)

            result["Resultats_Analytiques"]["Graphique_Fichier"] = GRAPH_URL_RETURN
        
        except Exception as e:
            result["Resultats_Analytiques"]["Erreur_Calcul_ANOVA"] = f"Calcul ANOVA impossible: {str(e)}"
            result["Resultats_Analytiques"]["Erreur_Graphique"] = "Impossible de générer le graphique: " + str(e)


    result["Nom_Variable_A"] = col_a
    result["Nom_Variable_B"] = col_b
    
    return result

# ======================================================================
# FLASK API
# ======================================================================

app = Flask(__name__)

@app.route('/api/analyze', methods=['POST'])
def analyze_data():
    """ Reçoit les données JSON, exécute l'analyse et renvoie le résultat. """
    
    try:
        data_json = request.get_json()
        col_a = data_json.get('col_a_name')
        col_b = data_json.get('col_b_name')
        data_dict = data_json.get('data')

        if not all([col_a, col_b, data_dict]):
            return jsonify({"error": "Paramètres manquants (col_a_name, col_b_name, data) ."}), 400

    except Exception as e:
        return jsonify({"error": f"Erreur de traitement des données: {str(e)}"}), 500

    try:
        df = pd.DataFrame(data_dict)
    except Exception as e:
        return jsonify({"error": f"Impossible de créer le DataFrame: {str(e)}"}), 500

    try:
        result = analyze_comparison(df, col_a, col_b)
        
        if "error" in result:
             return jsonify(result), 400
             
        return jsonify(result), 200
        
    except Exception as e:
        hata_mesaji = traceback.format_exc()
        return jsonify({"error": f"Erreur inattendue pendant l'analyse: {hata_mesaji}"}), 500


if __name__ == '__main__':
    print("Flask API en cours d'exécution... (http://127.0.0.1:5000/api/analyze)")
    app.run(debug=True, host='127.0.0.1', port=5000)




